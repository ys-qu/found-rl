# @package _group_
entry_point: agents.rl_vlm.models.drqv2:DrQv2Vlm
kwargs:
  learning_rate: 1e-4
  buffer_size: 150_000  # eu: {n_envs=1, dict_replay_buffer_size=70_000, replay_buffer_size=140_000}
  learning_starts: 1024
  batch_size: 256  # 128
  tau: 0.005
  gamma: 0.99
  train_freq: 1
  gradient_steps: 1
  optimize_memory_usage: false  # DictReplayBuffer doesn't support it
  tensorboard_log: null
  verbose: 1
  device: "auto"
  use_vlm: &use_vlm 'r_clip'  # pvp awac r_clip
  imitation_coef: 0.5
  stddev_schedule: 'linear(1.0,0.1,100000)'
  stddev_clip: 0.3
  replay_buffer_class: agents.rl_vlm.models.replay_buffer:DictReplayBufferVlm
  replay_buffer_kwargs:
    handle_timeout_termination: true  # false if optimize_memory_usage: true
    use_vlm: *use_vlm
    use_prioritized: false
    n_steps: 1        # Enable 3-step returns for better credit assignment
    gamma: 0.99       # Discount factor for n-step returns
  policy_kwargs:
    features_extractor_class: agents.rl_vlm.models.torch_layers:LiteXtMaCNN
    features_extractor_kwargs:
      features_dim: 256
      states_neurons: [256,256]

